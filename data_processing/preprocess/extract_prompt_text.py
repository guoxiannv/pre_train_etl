#!/usr/bin/env python3
"""
ä»JSONLæ–‡ä»¶çš„promptå­—æ®µä¸­æå–ä¸‰æ®µå†…å®¹å¹¶æ‹¼æ¥æˆæ–°çš„textå­—æ®µ
åŒæ—¶å°†<unused98>æ ‡ç­¾æ›¿æ¢æˆresponseå­—æ®µä¸­```arkts\nå’Œ\n```ä¹‹é—´çš„å†…å®¹
æ‰¹é‡å¤„ç†bg_dataæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
ä¸ºæ¯æ¡è®°å½•ç”ŸæˆåŸºäºpathçš„ç¨³å®šIDï¼Œå¹¶æ ‡å‡†åŒ–å­—æ®µå
"""

import json
import re
import os
import hashlib
from pathlib import Path
from typing import List


def extract_text_from_prompt(prompt: str) -> str:
    """
    ä»promptä¸­æå–ä¸‰æ®µå†…å®¹å¹¶æ‹¼æ¥ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼æ ¼å¼
    
    Args:
        prompt: åŒ…å«ä¸‰æ®µä»£ç çš„promptå­—ç¬¦ä¸²
        
    Returns:
        æ‹¼æ¥åçš„textå­—ç¬¦ä¸²
    """
    if not prompt or not isinstance(prompt, str):
        return ""
    
    try:
        # å®šä¹‰æå–æ¨¡å¼ï¼Œä¿ç•™å‰åç©ºæ ¼
        patterns = {
            'first': r'The context above the method is:\n```arkts\n(.*?)```\n\nAnd here is the code snippet you are asked to complete',
            'second': r'And here is the code snippet you are asked to complete:\n```arkts\n(.*?)```\n\nEnsure that only missing codes',
            'third': r'The context below the method is:\n```arkts\n(.*?)```\n\nThe context above the method is'
        }
        
        extracted_parts = {}
        
        # æå–ä¸‰æ®µå†…å®¹ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼
        for part_name, pattern in patterns.items():
            match = re.search(pattern, prompt, re.DOTALL)
            if match:
                # ä¸ä½¿ç”¨strip()ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼
                extracted_parts[part_name] = match.group(1)
            else:
                print(f"è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ° {part_name} éƒ¨åˆ†")
                extracted_parts[part_name] = ""
        
        # æ‹¼æ¥ä¸‰æ®µå†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼
        combined_text = (
            extracted_parts.get('first', '') + '\n\n' + 
            extracted_parts.get('second', '') + '\n\n' + 
            extracted_parts.get('third', '')
        )
        
        # åªåœ¨æœ€åå»é™¤é¦–å°¾çš„ç©ºç™½è¡Œï¼Œä½†ä¿ç•™å†…å®¹ä¸­çš„ç©ºæ ¼
        return combined_text.rstrip('\n')
        
    except Exception as e:
        print(f"æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return ""


def extract_response_code(response: str) -> str:
    """
    ä»responseå­—æ®µä¸­æå–```arkts\nå’Œ\n```ä¹‹é—´çš„ä»£ç å†…å®¹ï¼Œä¿ç•™ç©ºæ ¼
    
    Args:
        response: responseå­—æ®µå­—ç¬¦ä¸²
        
    Returns:
        æå–çš„ä»£ç å†…å®¹
    """
    if not response or not isinstance(response, str):
        return ""
    
    try:
        # åŒ¹é…```arkts\nå’Œ\n```ä¹‹é—´çš„å†…å®¹
        pattern = r'```arkts\n(.*?)\n```'
        match = re.search(pattern, response, re.DOTALL)
        
        if match:
            # ä¿ç•™åŸæœ‰ç©ºæ ¼ï¼Œä¸ä½¿ç”¨strip()
            return match.group(1)
        else:
            print("è­¦å‘Šï¼šæ— æ³•åœ¨responseä¸­æ‰¾åˆ°```arkts\n...\n```æ ¼å¼çš„ä»£ç ")
            return ""
            
    except Exception as e:
        print(f"æå–responseä»£ç æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return ""


def replace_unused98_tags(text: str, response_code: str) -> str:
    """
    å°†æ–‡æœ¬ä¸­çš„<unused98>æ ‡ç­¾æ›¿æ¢æˆresponseä»£ç ï¼Œä¿ç•™ç©ºæ ¼æ ¼å¼
    
    Args:
        text: åŒ…å«<unused98>æ ‡ç­¾çš„æ–‡æœ¬
        response_code: è¦æ›¿æ¢çš„ä»£ç å†…å®¹
        
    Returns:
        æ›¿æ¢åçš„æ–‡æœ¬
    """
    if not text or not isinstance(text, str):
        return text
    
    if not response_code:
        print("è­¦å‘Šï¼šresponse_codeä¸ºç©ºï¼Œæ— æ³•æ›¿æ¢<unused98>æ ‡ç­¾")
        return text
    
    try:
        # æ›¿æ¢æ‰€æœ‰<unused98>æ ‡ç­¾
        replaced_text = text.replace('<unused98>', response_code)
        
        # ç»Ÿè®¡æ›¿æ¢æ¬¡æ•°
        original_count = text.count('<unused98>')
        if original_count > 0:
            print(f"æˆåŠŸæ›¿æ¢ {original_count} ä¸ª<unused98>æ ‡ç­¾")
        
        return replaced_text
        
    except Exception as e:
        print(f"æ›¿æ¢<unused98>æ ‡ç­¾æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return text


def safe_json_loads(line: str, line_num: int) -> dict:
    """
    å®‰å…¨åœ°è§£æJSONè¡Œï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    
    Args:
        line: JSONå­—ç¬¦ä¸²
        line_num: è¡Œå·ï¼ˆç”¨äºé”™è¯¯æŠ¥å‘Šï¼‰
        
    Returns:
        è§£æåçš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºå­—å…¸
    """
    try:
        return json.loads(line.strip())
    except json.JSONDecodeError as e:
        print(f"ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}")
        print(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")  # åªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
        return {}
    except Exception as e:
        print(f"ç¬¬ {line_num} è¡Œå¤„ç†å¤±è´¥: {e}")
        return {}


def generate_stable_id(relative_path: str) -> str:
    """
    åŸºäºrelativePathç”Ÿæˆç¨³å®šçš„ID
    
    Args:
        relative_path: ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²
        
    Returns:
        64ä½åå…­è¿›åˆ¶SHA256å“ˆå¸ŒID
    """
    if not relative_path or not isinstance(relative_path, str):
        # å¦‚æœæ²¡æœ‰relativePathï¼Œç”Ÿæˆä¸€ä¸ªéšæœºID
        import uuid
        return str(uuid.uuid4())
    
    try:
        # ä½¿ç”¨SHA256å“ˆå¸Œç”Ÿæˆç¨³å®šID
        stable_id = hashlib.sha256(relative_path.encode('utf-8')).hexdigest()
        return stable_id
    except Exception as e:
        print(f"ç”ŸæˆIDæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # å‡ºé”™æ—¶ç”ŸæˆéšæœºID
        import uuid
        return str(uuid.uuid4())


def extract_project_info_from_repo_url(repo_url: str) -> tuple:
    """
    ä»repoUrlä¸­æå–project_nameå’Œpathä¿¡æ¯
    
    Args:
        repo_url: ä»“åº“URLå­—ç¬¦ä¸²
        
    Returns:
        (project_name, path) å…ƒç»„ï¼Œä¸¤è€…éƒ½æ˜¯repo_name
    """
    if not repo_url or not isinstance(repo_url, str):
        return "", ""
    
    try:
        # ç§»é™¤.gitåç¼€
        if repo_url.endswith('.git'):
            repo_url = repo_url[:-4]
        
        # åˆ†å‰²URLï¼Œè·å–æœ€åä¸€éƒ¨åˆ†
        parts = repo_url.split('/')
        if len(parts) >= 1:
            # è·å–æœ€åä¸€éƒ¨åˆ†ï¼šrepo_name
            repo_name = parts[-1]  # repo_name
            # project_nameå’Œpathéƒ½ä½¿ç”¨repo_name
            return repo_name, repo_name
        else:
            return "", ""
    except Exception as e:
        print(f"è§£ærepoUrlæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return "", ""

def process_jsonl_file(input_file: str, output_file: str) -> dict:
    """
    å¤„ç†å•ä¸ªJSONLæ–‡ä»¶ï¼Œä¸ºæ¯æ¡è®°å½•æ·»åŠ textå­—æ®µï¼Œå¹¶æ›¿æ¢<unused98>æ ‡ç­¾
    åŒæ—¶ä¸ºæ¯æ¡è®°å½•ç”ŸæˆåŸºäºpathçš„ç¨³å®šIDï¼Œå¹¶æ ‡å‡†åŒ–å­—æ®µå
    
    Args:
        input_file: è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
    
    # è¯»å–æ•°æ®
    try:
        data = []
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue
                
                record = safe_json_loads(line, line_num)
                if record:  # åªæ·»åŠ æˆåŠŸè§£æçš„è®°å½•
                    data.append(record)
                else:
                    print(f"è·³è¿‡ç¬¬ {line_num} è¡Œï¼ˆè§£æå¤±è´¥ï¼‰")
        
        print(f"æˆåŠŸè¯»å– {len(data)} æ¡æœ‰æ•ˆè®°å½•")
        
        if len(data) == 0:
            print("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•è®°å½•ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
            return {
                'total_records': 0,
                'processed_count': 0,
                'skipped_count': 0,
                'unused98_replaced_count': 0,
                'id_generated_count': 0,
                'fields_renamed': 0
            }
            
    except FileNotFoundError:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return {
            'total_records': 0,
            'processed_count': 0,
            'skipped_count': 0,
            'unused98_replaced_count': 0,
            'id_generated_count': 0,
            'fields_renamed': 0
        }
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return {
            'total_records': 0,
            'processed_count': 0,
            'skipped_count': 0,
            'unused98_replaced_count': 0,
            'id_generated_count': 0,
            'fields_renamed': 0
        }
    
    # å¤„ç†æ¯æ¡è®°å½•
    processed_count = 0
    skipped_count = 0
    unused98_replaced_count = 0
    id_generated_count = 0
    fields_renamed_count = 0
    
    for i, record in enumerate(data):
        if 'prompt' not in record:
            print(f"è­¦å‘Šï¼šç¬¬ {i+1} æ¡è®°å½•ç¼ºå°‘ 'prompt' å­—æ®µ")
            record['text'] = ""
            skipped_count += 1
            continue
        
        # å­—æ®µåæ ‡å‡†åŒ–å’Œå­—æ®µå€¼å¤„ç†
        # 1. å¤„ç†projectNameå­—æ®µ
        if 'projectName' in record:
            # å¦‚æœå­˜åœ¨projectNameï¼Œé‡å‘½åä¸ºproject_name
            record['project_name'] = record.pop('projectName')
            fields_renamed_count += 1
            print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šå­—æ®µå 'projectName' å·²æ”¹ä¸º 'project_name'")
        elif 'project_name' not in record:
            # å¦‚æœæ—¢æ²¡æœ‰projectNameä¹Ÿæ²¡æœ‰project_nameï¼Œä»repoUrlæå–
            repo_url = record.get('repoUrl', '')
            if repo_url:
                project_name, _ = extract_project_info_from_repo_url(repo_url)
                if project_name:
                    record['project_name'] = project_name
                    print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šä»repoUrlæå–project_name: '{project_name}'")
        
        # 2. å¤„ç†relativePathå­—æ®µ
        if 'relativePath' in record:
            # å¦‚æœå­˜åœ¨relativePathï¼Œé‡å‘½åä¸ºpath
            record['path'] = record.pop('relativePath')
            fields_renamed_count += 1
            print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šå­—æ®µå 'relativePath' å·²æ”¹ä¸º 'path'")
        elif 'path' not in record:
            # å¦‚æœæ—¢æ²¡æœ‰relativePathä¹Ÿæ²¡æœ‰pathï¼Œä»repoUrlæå–
            repo_url = record.get('repoUrl', '')
            if repo_url:
                _, path = extract_project_info_from_repo_url(repo_url)
                if path:
                    record['path'] = path
                    print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šä»repoUrlæå–path: '{path}'")
        
        # ç”ŸæˆåŸºäºpathçš„ç¨³å®šID
        file_path = record.get('path', '')
        if file_path:
            record['id'] = generate_stable_id(file_path)
            id_generated_count += 1
            print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šåŸºäºè·¯å¾„ '{file_path}' ç”ŸæˆID: {record['id'][:8]}...")
        else:
            print(f"è­¦å‘Šï¼šç¬¬ {i+1} æ¡è®°å½•ç¼ºå°‘ 'path' å­—æ®µï¼Œå°†ç”ŸæˆéšæœºID")
            record['id'] = generate_stable_id("")
            id_generated_count += 1
        
        # æå–textå†…å®¹
        text_content = extract_text_from_prompt(record['prompt'])
        record['text'] = text_content
        processed_count += 1
        
        # å¤„ç†<unused98>æ ‡ç­¾æ›¿æ¢
        if 'response' in record and '<unused98>' in text_content:
            response_code = extract_response_code(record['response'])
            if response_code:
                record['text'] = replace_unused98_tags(text_content, response_code)
                unused98_replaced_count += 1
                print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šæˆåŠŸæ›¿æ¢<unused98>æ ‡ç­¾")
        
        if (i + 1) % 100 == 0:
            print(f"å·²å¤„ç† {i + 1}/{len(data)} æ¡è®°å½•")
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for record in data:
                json.dump(record, f, ensure_ascii=False)
                f.write('\n')
        print(f"æˆåŠŸä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return {
            'total_records': len(data),
            'processed_count': 0,
            'skipped_count': 0,
            'unused98_replaced_count': 0,
            'id_generated_count': 0
        }
    
    # è¿”å›ç»Ÿè®¡ä¿¡æ¯
    return {
        'total_records': len(data),
        'processed_count': processed_count,
        'skipped_count': skipped_count,
        'unused98_replaced_count': unused98_replaced_count,
        'id_generated_count': id_generated_count,
        'fields_renamed': fields_renamed_count
    }


def get_jsonl_files(input_dir: str) -> List[str]:
    """
    è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        
    Returns:
        JSONLæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    jsonl_files = []
    
    try:
        input_path = Path(input_dir)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return jsonl_files
        
        # æŸ¥æ‰¾æ‰€æœ‰.jsonlæ–‡ä»¶
        for file_path in input_path.glob("*.jsonl"):
            jsonl_files.append(str(file_path))
        
        # ä¹ŸæŸ¥æ‰¾.jsonæ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        for file_path in input_path.glob("*.json"):
            jsonl_files.append(str(file_path))
        
        print(f"åœ¨ {input_dir} ç›®å½•ä¸‹æ‰¾åˆ° {len(jsonl_files)} ä¸ªJSONLæ–‡ä»¶")
        
    except Exception as e:
        print(f"è·å–JSONLæ–‡ä»¶åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    return jsonl_files


def batch_process_files(input_dir: str, output_dir: str) -> None:
    """
    æ‰¹é‡å¤„ç†æŒ‡å®šè¾“å…¥ç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    """
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†æ–‡ä»¶...")
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 60)
    
    # è·å–æ‰€æœ‰JSONLæ–‡ä»¶
    jsonl_files = get_jsonl_files(input_dir)
    
    if not jsonl_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•JSONLæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è¾“å…¥ç›®å½•")
        return
    
    # æ‰¹é‡å¤„ç†
    total_stats = {
        'total_files': len(jsonl_files),
        'total_records': 0,
        'total_processed': 0,
        'total_skipped': 0,
        'total_unused98_replaced': 0,
        'total_id_generated': 0,
        'total_fields_renamed': 0
    }
    
    for i, input_file in enumerate(jsonl_files, 1):
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i}/{len(jsonl_files)}: {os.path.basename(input_file)}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        input_path = Path(input_file)
        output_file = Path(output_dir) / f"{input_path.stem}_with_text{input_path.suffix}"
        
        # å¤„ç†æ–‡ä»¶
        stats = process_jsonl_file(input_file, str(output_file))
        
        # ç´¯è®¡ç»Ÿè®¡ä¿¡æ¯
        total_stats['total_records'] += stats['total_records']
        total_stats['total_processed'] += stats['processed_count']
        total_stats['total_skipped'] += stats['skipped_count']
        total_stats['total_unused98_replaced'] += stats['unused98_replaced_count']
        total_stats['total_id_generated'] += stats['id_generated_count']
        total_stats['total_fields_renamed'] += stats['fields_renamed']
        
        print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(input_file)}")
        print(f"   è®°å½•æ•°: {stats['total_records']}, å¤„ç†: {stats['processed_count']}, è·³è¿‡: {stats['skipped_count']}, æ›¿æ¢æ ‡ç­¾: {stats['unused98_replaced_count']}, ç”ŸæˆID: {stats['id_generated_count']}, å­—æ®µé‡å‘½å: {stats['fields_renamed']}")
    
    # è¾“å‡ºæ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ¯ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"æ€»æ–‡ä»¶æ•°: {total_stats['total_files']}")
    print(f"æ€»è®°å½•æ•°: {total_stats['total_records']}")
    print(f"æ€»å¤„ç†æ•°: {total_stats['total_processed']}")
    print(f"æ€»è·³è¿‡æ•°: {total_stats['total_skipped']}")
    print(f"æ€»æ›¿æ¢æ ‡ç­¾æ•°: {total_stats['total_unused98_replaced']}")
    print(f"æ€»ç”ŸæˆIDæ•°: {total_stats['total_id_generated']}")
    print(f"æ€»å­—æ®µé‡å‘½åæ•°: {total_stats['total_fields_renamed']}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")


def check_file_format(input_file: str) -> bool:
    """
    æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ ¼å¼æ˜¯å¦æ­£ç¡®
    """
    print(f"æ£€æŸ¥æ–‡ä»¶æ ¼å¼: {input_file}")
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            # è¯»å–å‰å‡ è¡Œè¿›è¡Œæ£€æŸ¥
            for i, line in enumerate(f, 1):
                if i > 5:  # åªæ£€æŸ¥å‰5è¡Œ
                    break
                    
                line = line.strip()
                if not line:
                    continue
                    
                try:
                    record = json.loads(line)
                    if not isinstance(record, dict):
                        print(f"ç¬¬ {i} è¡Œï¼šä¸æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡")
                        return False
                    print(f"ç¬¬ {i} è¡Œï¼šæ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«å­—æ®µ: {list(record.keys())}")
                except json.JSONDecodeError as e:
                    print(f"ç¬¬ {i} è¡Œï¼šJSONæ ¼å¼é”™è¯¯ - {e}")
                    print(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")
                    return False
                    
        print("æ–‡ä»¶æ ¼å¼æ£€æŸ¥å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"æ£€æŸ¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    current_dir = Path(__file__).parent
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡å¤„ç†JSONLæ–‡ä»¶ï¼Œæå–textå†…å®¹å¹¶æ›¿æ¢<unused98>æ ‡ç­¾ï¼ŒåŒæ—¶ç”ŸæˆåŸºäºpathçš„ç¨³å®šIDï¼Œå¹¶æ ‡å‡†åŒ–å­—æ®µå')
    parser.add_argument('--input-dir', default=str(current_dir / 'bg_data'), help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ä¸è„šæœ¬åŒçº§ç›®å½•ä¸‹çš„bg_dataï¼‰')
    parser.add_argument('--output-dir', default=str(current_dir / 'trans_text_data'), help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ä¸è„šæœ¬åŒçº§ç›®å½•ä¸‹çš„trans_text_dataï¼‰')
    parser.add_argument('--single-file', help='å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--check', action='store_true', help='åªæ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼Œä¸è¿›è¡Œå¤„ç†')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†å•ä¸ªæ–‡ä»¶
    if args.single_file:
        if not Path(args.single_file).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.single_file}")
            return
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        input_path = Path(args.single_file)
        output_file = Path(args.output_dir) / f"{input_path.stem}_with_text{input_path.suffix}"
        
        # å…ˆæ£€æŸ¥æ–‡ä»¶æ ¼å¼
        if not check_file_format(args.single_file):
            print("æ–‡ä»¶æ ¼å¼æœ‰é—®é¢˜ï¼Œè¯·ä¿®å¤åå†è¯•")
            return
        
        # å¤„ç†å•ä¸ªæ–‡ä»¶
        stats = process_jsonl_file(args.single_file, str(output_file))
        print(f"\nå¤„ç†å®Œæˆï¼")
        print(f"è®°å½•æ•°: {stats['total_records']}")
        print(f"å¤„ç†æ•°: {stats['processed_count']}")
        print(f"è·³è¿‡æ•°: {stats['skipped_count']}")
        print(f"æ›¿æ¢æ ‡ç­¾æ•°: {stats['unused98_replaced_count']}")
        print(f"ç”ŸæˆIDæ•°: {stats['id_generated_count']}")
        print(f"å­—æ®µé‡å‘½åæ•°: {stats['fields_renamed']}")
        
    else:
        # æ‰¹é‡å¤„ç†
        input_dir = args.input_dir
        output_dir = args.output_dir
        
        if not Path(input_dir).exists():
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        # æ‰¹é‡å¤„ç†æ–‡ä»¶
        batch_process_files(input_dir, output_dir)


if __name__ == "__main__":
    main() 