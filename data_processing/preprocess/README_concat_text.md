# Concat Text - 统一文本拼接处理器

## 📋 概述

`concat_text.py` 是一个统一的数据预处理工具，专门用于处理两种不同格式的代码数据，并将它们转换为统一的输出格式。该工具合并了原有的 `concatenate_fields.py` 和 `extract_prompt_text.py` 两个脚本的功能，提供了一站式的数据处理解决方案。

## 🎯 主要功能

### 1. Fields格式数据处理
- **功能**：拼接三个字段内容
- **输入字段**：`above_functions` + `source_method_code` + `below_functions`
- **处理逻辑**：
  - 智能处理字段值（字符串、列表、字典等类型）
  - 保留原始空格和换行格式
  - 直接拼接三个字段内容
- **适用场景**：结构化代码数据，包含明确的上下文、代码片段和后续代码

### 2. Prompt格式数据处理
- **功能**：从prompt字段中提取三段代码内容并处理标签替换
- **输入字段**：`prompt`（包含三段代码的文本）
- **处理逻辑**：
  - 使用正则表达式提取三段代码内容
  - 处理 `<unused98>` 标签替换
  - 提取 `external_imported` 信息
  - 自动过滤替换失败的记录
- **适用场景**：自然语言prompt数据，包含代码补全任务

### 3. 数据标准化
- **字段重命名**：
  - `projectName` → `project_name`
  - `filePath` → `path`
  - `relativePath` → `path`
- **ID生成**：基于文件路径生成SHA256哈希的稳定唯一标识
- **项目信息提取**：从 `repoUrl` 自动提取项目名称和路径信息

## 📁 输入输出配置

### 输入目录
- **Fields格式数据**：`bg_data_select/`（默认）
- **Prompt格式数据**：`bg_data/`（默认）

### 输出目录
- **统一输出**：`trans_text_data/`
- **文件命名**：`{原文件名}_with_text.jsonl`

### 数据流向
```
bg_data_select/ (Fields格式) ──┐
                                ├──→ concat_text.py ──→ trans_text_data/
bg_data/ (Prompt格式) ─────────┘
```

## 🚀 使用方法

### 基本命令
```bash
# 处理两种格式数据（默认行为）
python data_processing/preprocess/concat_text.py

# 只处理Fields格式数据
python data_processing/preprocess/concat_text.py --fields-only

# 只处理Prompt格式数据
python data_processing/preprocess/concat_text.py --prompt-only

# 强制指定数据类型
python data_processing/preprocess/concat_text.py --force-type fields
```

### 高级选项
```bash
# 自定义输入输出目录
python data_processing/preprocess/concat_text.py \
    --fields-dir custom_fields \
    --prompt-dir custom_prompts \
    --output-dir custom_output

# 处理单个文件
python data_processing/preprocess/concat_text.py \
    --single-file path/to/file.jsonl

# 处理两种格式数据
python data_processing/preprocess/concat_text.py --both
```

## 🔧 核心算法

### Fields格式处理流程
1. **字段标准化**：重命名字段，统一命名规范
2. **ID生成**：基于文件路径生成稳定ID
3. **字段拼接**：智能处理不同类型字段值，拼接三个字段
4. **质量检查**：验证必需字段是否存在

### Prompt格式处理流程
1. **字段标准化**：重命名字段，从repoUrl提取项目信息
2. **ID生成**：基于文件路径生成稳定ID
3. **文本提取**：使用正则表达式提取三段代码内容
4. **标签替换**：处理 `<unused98>` 标签替换
5. **外部信息提取**：提取 `external_imported` 信息
6. **质量过滤**：自动过滤替换失败的记录

### 标签替换逻辑
- **检测标签**：在prompt中查找 `<unused98>` 标签
- **提取代码**：从response字段中提取 ```arkts...``` 格式的代码
- **执行替换**：将标签替换为实际代码内容
- **验证结果**：检查替换后是否还有剩余标签
- **自动过滤**：只保存完全替换成功的记录

## 📊 输出统计

### 处理统计信息
- **总记录数**：处理的记录总数
- **Fields格式处理**：成功处理的Fields格式记录数
- **Prompt格式处理**：成功处理的Prompt格式记录数
- **跳过记录**：处理过程中跳过的记录数
- **替换标签**：成功替换的 `<unused98>` 标签数
- **生成ID**：生成的唯一标识符数量
- **字段重命名**：标准化的字段数量
- **提取external_imported**：成功提取的外部导入信息数量
- **标签替换失败**：替换失败的记录数量

### 输出示例
```
🎯 处理完成！
总记录数: 46082
Fields格式处理: 0
Prompt格式处理: 46082
跳过记录: 0
未知类型: 0
缺少字段: 0
替换标签: 46081
生成ID: 46082
字段重命名: 92164
提取external_imported: 12345
标签替换失败: 1
标签替换失败的记录ID: ['abc123def456']

✅ 处理后的数据已保存到: output_with_text.jsonl
✅ 实际保存记录数: 46081/46082
⚠️  过滤掉了 1 条替换失败的记录
```

## 🔍 数据质量保证

### 自动过滤机制
- **替换失败检测**：自动识别 `<unused98>` 标签替换失败的记录
- **数据完整性**：只输出完全处理成功的记录
- **质量统计**：提供详细的处理统计和失败记录ID

### 错误处理
- **JSON解析错误**：安全处理格式错误的JSON行
- **字段缺失**：优雅处理缺少必需字段的记录
- **类型转换**：智能处理各种数据类型的字段值

## 📈 性能优化

### 高效处理
- **目录级处理**：根据输入目录直接确定数据类型，避免逐条检测
- **批量操作**：支持目录级别的批量文件处理
- **内存优化**：流式处理大文件，避免内存溢出

### 进度监控
- **实时进度**：每1000条记录显示处理进度
- **详细日志**：提供处理过程中的关键信息
- **错误定位**：精确定位处理失败的记录

## 🎨 输出格式

### 标准字段
所有输出记录都包含以下字段：
- `text`：处理后的文本内容
- `id`：基于文件路径的稳定唯一标识
- `project_name`：项目名称
- `path`：文件路径
- `external_imported`：外部导入信息（仅Prompt格式）

### 保留字段
- 所有原始字段保持不变
- 标准化后的字段名（如 `project_name`、`path`）

## 🔧 技术特性

### 编程语言
- **Python 3.6+**：支持现代Python特性
- **类型提示**：完整的类型注解，提高代码可读性
- **错误处理**：健壮的错误处理和日志记录

### 依赖库
- **标准库**：json, re, os, sys, hashlib, pathlib, typing, argparse
- **无外部依赖**：开箱即用，无需安装额外包

### 兼容性
- **跨平台**：支持Windows、macOS、Linux
- **编码支持**：UTF-8编码，支持中文和特殊字符
- **文件格式**：支持JSONL和JSON格式

## 📝 使用场景

### 适用场景
1. **代码数据预处理**：为机器学习模型准备训练数据
2. **数据格式统一**：将不同来源的代码数据标准化
3. **批量数据处理**：处理大量代码文件的自动化任务
4. **数据质量检查**：识别和处理有问题的数据记录

### 典型应用
- **代码补全模型训练**：处理代码补全任务的数据集
- **代码分析工具**：为代码分析提供标准化的输入
- **数据管道集成**：作为ETL流程的一部分
- **研究数据准备**：为代码相关研究准备数据集

## 🚨 注意事项

### 数据要求
- **Fields格式**：必须包含 `above_functions`、`source_method_code`、`below_functions` 三个字段
- **Prompt格式**：必须包含 `prompt` 字段，且格式符合预期结构
- **文件格式**：输入文件必须是有效的JSONL或JSON格式

### 性能考虑
- **大文件处理**：建议分批处理超大文件
- **内存使用**：处理过程中会占用一定内存
- **磁盘空间**：确保有足够的磁盘空间存储输出文件

### 错误处理
- **失败记录**：替换失败的记录会被自动过滤，不会出现在输出中
- **日志记录**：所有错误和警告都会记录在控制台输出中
- **统计信息**：失败记录的ID会显示在最终统计中

## 🔮 未来扩展

### 可能的增强功能
1. **更多数据格式支持**：支持其他类型的代码数据格式
2. **配置化处理**：支持配置文件定义处理规则
3. **并行处理**：支持多进程并行处理大文件
4. **数据验证**：增加更严格的数据质量检查
5. **输出格式**：支持更多输出格式（如Parquet、CSV等）

### 集成可能性
- **API接口**：提供REST API接口
- **Web界面**：开发Web管理界面
- **调度系统**：集成到数据调度系统中
- **监控告警**：添加处理监控和告警功能

## 📞 技术支持

### 问题排查
1. **检查输入文件格式**：确保JSON格式正确
2. **验证字段完整性**：检查必需字段是否存在
3. **查看错误日志**：仔细阅读控制台输出的错误信息
4. **检查文件权限**：确保有读写权限

### 常见问题
- **字段缺失错误**：检查输入数据是否包含必需字段
- **编码问题**：确保文件使用UTF-8编码
- **内存不足**：分批处理大文件
- **路径问题**：检查输入输出路径是否正确

---

*本文档描述了 `concat_text.py` 的完整功能和使用方法。如有问题，请查看代码注释或联系开发团队。*
