#!/usr/bin/env python3
"""
ç»Ÿè®¡æŒ‡å®šç›®å½•ä¸‹æ¯ä¸ª JSONL æ–‡ä»¶å†…ï¼š
1) repoUrl ä¸ºç©º/ç¼ºå¤± çš„æ•°é‡ï¼ˆé€æ–‡ä»¶ç»Ÿè®¡å¹¶è¾“å‡ºæ•°å­—ï¼‰
2) ä½¿ç”¨æ¯æ¡è®°å½•çš„ project_name ä¸ arkts_repos.json çš„ git_url è¿›è¡Œâ€œåŒ…å«åŒ¹é…â€ï¼ˆgit_url åŒ…å« project_name å³è§†ä¸ºåŒ¹é…ï¼‰ï¼Œç»Ÿè®¡æœªåŒ¹é…çš„æ•°é‡ï¼Œå¹¶å¯¼å‡ºæœªåŒ¹é…çš„ project_name æ¸…å•æ–‡ä»¶ï¼ˆé€æ–‡ä»¶è¾“å‡ºï¼‰ã€‚

ç”¨æ³•:
  python check_repo_urls.py --input-dir <ç›®å½•> --repos-file <arkts_repos.json>
é»˜è®¤ input-dir ä¸ºè„šæœ¬åŒçº§çš„ trans_text_dataï¼Œé»˜è®¤ repos-file ä¸ºè„šæœ¬åŒçº§çš„ arkts_repos.jsonã€‚
"""

import os
import json
import argparse
from pathlib import Path
from typing import Dict, Any, Set, Tuple, List


def load_repo_git_urls(repos_file: Path) -> List[str]:
    """
    ä» arkts_repos.json åŠ è½½ git_url åˆ—è¡¨ã€‚
    æ”¯æŒä¸¤ç§æ•°æ®ç»“æ„ï¼š
      - åˆ—è¡¨: [{"git_url": "..."}, ...]
      - å­—å…¸: {"repos": [{"git_url": "..."}, ...]}
    """
    if not repos_file.exists():
        print(f"âŒ repos æ–‡ä»¶ä¸å­˜åœ¨: {repos_file}")
        return []
    try:
        with open(repos_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        items = data.get('repos', data) if isinstance(data, dict) else data
        urls: List[str] = []
        for it in (items or []):
            if isinstance(it, dict):
                url = str(it.get('git_url', '') or '').strip()
                if url:
                    urls.append(url)
        return urls
    except Exception as e:
        print(f"âŒ è¯»å– repos æ–‡ä»¶å¤±è´¥: {e}")
        return []


def iter_jsonl_records(file_path: Path):
    """é€è¡Œè¯»å– JSONL è®°å½•ï¼Œè§£æå¤±è´¥çš„è¡Œè·³è¿‡ã€‚"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    yield json.loads(line)
                except json.JSONDecodeError:
                    print(f"   âš ï¸ JSONè§£æå¤±è´¥ï¼Œæ–‡ä»¶ {file_path.name} ç¬¬{line_num}è¡Œï¼Œå·²è·³è¿‡")
                    continue
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")


def analyze_file(jsonl_file: Path, repo_git_urls: List[str]) -> Tuple[int, int, Set[str], int]:
    """
    åˆ†æå•ä¸ª JSONL æ–‡ä»¶ï¼š
    è¿”å›: (total_records, missing_repo_url_count, unmatched_project_names(å»é‡), unmatched_count(æœªåŒ¹é…è®°å½•æ¡æ•°))
    """
    total_records = 0
    missing_repo_url = 0
    unmatched_project_names: Set[str] = set()
    unmatched_count = 0

    for rec in iter_jsonl_records(jsonl_file):
        total_records += 1
        # 1) ç»Ÿè®¡ repoUrl ä¸ºç©º/ç¼ºå¤±
        repo_url = str(rec.get('repoUrl') or '').strip()
        if not repo_url:
            missing_repo_url += 1
        # 2) project_name ä¸ git_url(åŒ…å«åŒ¹é…)ï¼ŒæŒ‰ '-' é€ä¸ªæ›¿æ¢å°è¯•
        project_name = str(rec.get('project_name') or '').strip()
        if project_name:
            matched = False
            # åŸå§‹åŒ¹é…
            for url in repo_git_urls:
                if url and project_name in url:
                    matched = True
                    break
            # é€ä¸ª '-' æ›¿æ¢ä¸º '/' å†åŒ¹é…
            if not matched and '-' in project_name:
                hyphen_positions = [i for i, ch in enumerate(project_name) if ch == '-']
                for pos in hyphen_positions:
                    alt_name = project_name[:pos] + '/' + project_name[pos+1:]
                    for url in repo_git_urls:
                        if url and alt_name in url:
                            matched = True
                            break
                    if matched:
                        break
            if not matched:
                unmatched_project_names.add(project_name)
                unmatched_count += 1

    return total_records, missing_repo_url, unmatched_project_names, unmatched_count


def main():
    parser = argparse.ArgumentParser(description='é€æ–‡ä»¶ç»Ÿè®¡ repoUrl ä¸ºç©ºæ•°é‡ä¸ project_name ä¸ git_url çš„åŒ…å«åŒ¹é…æœªå‘½ä¸­æ¸…å•')
    curdir = Path(__file__).parent
    parser.add_argument('--input-dir', default=str(curdir / 'trans_text_data'), help='è¾“å…¥ç›®å½•(é»˜è®¤: è„šæœ¬åŒçº§ trans_text_data)')
    parser.add_argument('--repos-file', default=str(curdir / 'arkts_repos.json'), help='reposæ–‡ä»¶è·¯å¾„(é»˜è®¤: è„šæœ¬åŒçº§ arkts_repos.json)')
    args = parser.parse_args()

    input_dir = Path(args.input_dir)
    repos_file = Path(args.repos_file)

    if not input_dir.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return

    repo_git_urls = load_repo_git_urls(repos_file)
    print(f"åŠ è½½ git_url æ•°é‡: {len(repo_git_urls)} æ¥è‡ª {repos_file}")

    jsonl_files = list(input_dir.glob('*.jsonl'))
    if not jsonl_files:
        print(f"âŒ æœªåœ¨ {input_dir} æ‰¾åˆ°ä»»ä½• JSONL æ–‡ä»¶")
        return

    print(f"åœ¨ {input_dir} å‘ç° {len(jsonl_files)} ä¸ª JSONL æ–‡ä»¶")

    # æ±‡æ€»ç»Ÿè®¡
    grand_total = 0
    grand_missing = 0
    grand_unmatched_projects: Set[str] = set()

    for idx, fp in enumerate(jsonl_files, 1):
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶ {idx}/{len(jsonl_files)}: {fp.name}")
        total, missing_cnt, unmatched_projects, unmatched_count = analyze_file(fp, repo_git_urls)

        # æ§åˆ¶å°æ‰“å°æ¯æ–‡ä»¶ç»Ÿè®¡ï¼ˆä¸è¾“å‡ºæ–‡ä»¶ï¼‰
        print(f"   repoUrl ä¸ºç©ºæ•°é‡: {missing_cnt}")
        print(f"   æœªåŒ¹é…çš„ project_name: {len(unmatched_projects)} (è®°å½•æ¡æ•°: {unmatched_count})")

        # æ±‡æ€»
        grand_total += total
        grand_missing += missing_cnt
        grand_unmatched_projects.update(unmatched_projects)

    # ç›®å½•çº§æ€»ç»“ä¸æœªåŒ¹é…æ¸…å•å¯¼å‡ºï¼ˆæ±‡æ€»ä¸€ä¸ªæ–‡ä»¶ï¼‰
    print("\n" + "=" * 60)
    print("ç»Ÿè®¡å®Œæˆ (ç›®å½•çº§)")
    print(f"æ€»è®°å½•æ•°: {grand_total}")
    print(f"repoUrl ç¼ºå¤±/ä¸ºç©º(åˆè®¡): {grand_missing}")
    print(f"project_name ä¸ git_url(åŒ…å«åŒ¹é…)æœªåŒ¹é…(å»é‡, åˆè®¡): {len(grand_unmatched_projects)}")

    # æ±‡æ€»ç”Ÿæˆä¸€ä¸ªæœªåŒ¹é…æ–‡ä»¶
    if grand_unmatched_projects:
        out_all = input_dir / 'unmatched_project_names.txt'
        try:
            with open(out_all, 'w', encoding='utf-8') as f:
                for name in sorted(grand_unmatched_projects):
                    f.write(name + '\n')
            print(f"æœªåŒ¹é…çš„ project_name æ¸…å•(æ±‡æ€»)å·²å¯¼å‡º: {out_all} (å…± {len(grand_unmatched_projects)} ä¸ª)")
        except Exception as e:
            print(f"âŒ å¯¼å‡ºæ±‡æ€»æœªåŒ¹é…æ¸…å•å¤±è´¥: {e}")


if __name__ == '__main__':
    main() 