#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„æ–‡æœ¬å¤„ç†è„šæœ¬
æ”¯æŒä¸¤ç§æ•°æ®æ ¼å¼çš„æ‹¼æ¥ï¼Œæœ€ç»ˆè¾“å‡ºåˆ°ç»Ÿä¸€ç›®å½•ï¼š
1. ä»promptå­—æ®µæå–ä¸‰æ®µå†…å®¹æ‹¼æ¥ï¼ˆextract_prompt_textåŠŸèƒ½ï¼‰
2. æ‹¼æ¥above_functions + source_method_code + below_functionsï¼ˆconcatenate_fieldsåŠŸèƒ½ï¼‰
"""

import json
import re
import os
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import argparse


class UnifiedTextProcessor:
    """ç»Ÿä¸€æ–‡æœ¬å¤„ç†å™¨"""
    
    def __init__(self, output_dir: str = "unified_output"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'prompt_type': {
                'total': 0, 'processed': 0, 'skipped': 0, 
                'unused98_replaced': 0, 'external_imported': 0
            },
            'fields_type': {
                'total': 0, 'processed': 0, 'skipped': 0, 'missing_fields': 0
            },
            'id_generated': 0,
            'fields_renamed': 0
        }
    
    def detect_data_type(self, record: Dict) -> str:
        """
        æ£€æµ‹æ•°æ®ç±»å‹
        
        Args:
            record: JSONLè®°å½•
            
        Returns:
            'prompt' æˆ– 'fields' æˆ– 'unknown'
        """
        if 'prompt' in record:
            return 'prompt'
        elif all(field in record for field in ['above_functions', 'source_method_code', 'below_functions']):
            return 'fields'
        else:
            return 'unknown'
    
    def extract_text_from_prompt(self, prompt: str) -> str:
        """
        ä»promptä¸­æå–ä¸‰æ®µå†…å®¹å¹¶æ‹¼æ¥ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼æ ¼å¼
        """
        if not prompt or not isinstance(prompt, str):
            return ""
        
        try:
            # å®šä¹‰æå–æ¨¡å¼ï¼Œä¿ç•™å‰åç©ºæ ¼
            patterns = {
                'first': r'The context above the method is:\n```arkts\n(.*?)```\n\nAnd here is the code snippet you are asked to complete',
                'second': r'And here is the code snippet you are asked to complete:\n```arkts\n(.*?)```\n\nEnsure that only missing codes',
                'third': r'The context below the method is:\n```arkts\n(.*?)```\n\nThe context above the method is'
            }
            
            extracted_parts = {}
            
            # æå–ä¸‰æ®µå†…å®¹ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼
            for part_name, pattern in patterns.items():
                match = re.search(pattern, prompt, re.DOTALL)
                if match:
                    extracted_parts[part_name] = match.group(1)
                else:
                    extracted_parts[part_name] = ""
            
            # æ‹¼æ¥ä¸‰æ®µå†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼
            combined_text = (
                extracted_parts.get('first', '') + '\n\n' + 
                extracted_parts.get('second', '') + '\n\n' + 
                extracted_parts.get('third', '')
            )
            
            return combined_text.rstrip('\n')
            
        except Exception as e:
            print(f"æå–promptå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""
    
    def extract_response_code(self, response: str) -> str:
        """ä»responseå­—æ®µä¸­æå–```arkts\nå’Œ\n```ä¹‹é—´çš„ä»£ç å†…å®¹"""
        if not response or not isinstance(response, str):
            return ""
        
        try:
            pattern = r'```arkts\n(.*?)\n```'
            match = re.search(pattern, response, re.DOTALL)
            return match.group(1) if match else ""
        except Exception as e:
            print(f"æå–responseä»£ç æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""
    
    def replace_unused98_tags(self, text: str, response_code: str) -> str:
        """å°†æ–‡æœ¬ä¸­çš„<unused98>æ ‡ç­¾æ›¿æ¢æˆresponseä»£ç """
        if not text or not isinstance(text, str) or not response_code:
            return text
        
        try:
            replaced_text = text.replace('<unused98>', response_code)
            original_count = text.count('<unused98>')
            if original_count > 0:
                self.stats['prompt_type']['unused98_replaced'] += original_count
            return replaced_text
        except Exception as e:
            print(f"æ›¿æ¢<unused98>æ ‡ç­¾æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return text
    
    def extract_external_imported(self, prompt: str) -> str:
        """æå–external_importedä¿¡æ¯"""
        if not prompt or not isinstance(prompt, str):
            return ""
        
        try:
            pattern = r'Below are some information from external classes imported by current file:\n```arkts\n(.*?)```'
            match = re.search(pattern, prompt, re.DOTALL)
            if match:
                self.stats['prompt_type']['external_imported'] += 1
                return match.group(1)
            return ""
        except Exception as e:
            print(f"æå–external_importedæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return ""
    
    def concatenate_fields(self, record: Dict) -> str:
        """æ‹¼æ¥ä¸‰ä¸ªå­—æ®µï¼šabove_functions + source_method_code + below_functions"""
        
        def process_field_value(value):
            if value is None:
                return ''
            elif isinstance(value, str):
                return value
            elif isinstance(value, (list, tuple)):
                if len(value) == 0:
                    return ''
                elif all(isinstance(item, str) for item in value):
                    return '\n'.join(item for item in value if item)
                else:
                    return str(value)
            elif isinstance(value, dict):
                try:
                    json_str = json.dumps(value, ensure_ascii=False)
                    return json_str[1:-1] if json_str.startswith('{') and json_str.endswith('}') else json_str
                except:
                    return str(value)
            else:
                return str(value)
        
        # è·å–ä¸‰ä¸ªå­—æ®µçš„å€¼
        above_functions = process_field_value(record.get('above_functions', ''))
        source_method_code = process_field_value(record.get('source_method_code', ''))
        below_functions = process_field_value(record.get('below_functions', ''))
        
        # ç›´æ¥æ‹¼æ¥ä¸‰ä¸ªå­—æ®µ
        return above_functions + source_method_code + below_functions
    
    def generate_stable_id(self, path: str) -> str:
        """åŸºäºpathç”Ÿæˆç¨³å®šçš„ID"""
        if not path or not isinstance(path, str):
            import uuid
            return str(uuid.uuid4())
        
        try:
            return hashlib.sha256(path.encode('utf-8')).hexdigest()
        except Exception as e:
            print(f"ç”ŸæˆIDæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import uuid
            return str(uuid.uuid4())
    
    def extract_project_info_from_repo_url(self, repo_url: str) -> Tuple[str, str]:
        """ä»repoUrlä¸­æå–project_nameå’Œpathä¿¡æ¯"""
        if not repo_url or not isinstance(repo_url, str):
            return "", ""
        
        try:
            if repo_url.endswith('.git'):
                repo_url = repo_url[:-4]
            
            parts = repo_url.split('/')
            if len(parts) >= 1:
                repo_name = parts[-1]
                return repo_name, repo_name
            else:
                return "", ""
        except Exception as e:
            print(f"è§£ærepoUrlæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return "", ""
    
    def standardize_fields(self, record: Dict, record_index: int) -> Dict:
        """æ ‡å‡†åŒ–å­—æ®µå"""
        # å¤„ç†projectNameå­—æ®µ
        if 'projectName' in record:
            record['project_name'] = record.pop('projectName')
            self.stats['fields_renamed'] += 1
            print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šå­—æ®µå 'projectName' å·²æ”¹ä¸º 'project_name'")
        elif 'project_name' not in record:
            repo_url = record.get('repoUrl', '')
            if repo_url:
                project_name, _ = self.extract_project_info_from_repo_url(repo_url)
                if project_name:
                    record['project_name'] = project_name
                    print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šä»repoUrlæå–project_name: '{project_name}'")
        
        # å¤„ç†relativePathå’ŒfilePathå­—æ®µ
        if 'relativePath' in record:
            record['path'] = record.pop('relativePath')
            self.stats['fields_renamed'] += 1
            print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šå­—æ®µå 'relativePath' å·²æ”¹ä¸º 'path'")
        elif 'filePath' in record:
            record['path'] = record.pop('filePath')
            self.stats['fields_renamed'] += 1
            print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šå­—æ®µå 'filePath' å·²æ”¹ä¸º 'path'")
        elif 'path' not in record:
            repo_url = record.get('repoUrl', '')
            if repo_url:
                _, path = self.extract_project_info_from_repo_url(repo_url)
                if path:
                    record['path'] = path
                    print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šä»repoUrlæå–path: '{path}'")
        
        return record
    
    def process_prompt_type(self, record: Dict, record_index: int) -> Dict:
        """å¤„ç†promptç±»å‹çš„æ•°æ®"""
        self.stats['prompt_type']['total'] += 1
        
        if 'prompt' not in record:
            print(f"è­¦å‘Šï¼šç¬¬ {record_index+1} æ¡è®°å½•ç¼ºå°‘ 'prompt' å­—æ®µ")
            record['text'] = ""
            self.stats['prompt_type']['skipped'] += 1
            return record
        
        # æå–textå†…å®¹
        text_content = self.extract_text_from_prompt(record['prompt'])
        record['text'] = text_content
        
        # æå–external_imported
        external_imported = self.extract_external_imported(record['prompt'])
        if external_imported:
            record['external_imported'] = external_imported
        
        # å¤„ç†<unused98>æ ‡ç­¾æ›¿æ¢
        if 'response' in record and '<unused98>' in text_content:
            response_code = self.extract_response_code(record['response'])
            if response_code:
                record['text'] = self.replace_unused98_tags(text_content, response_code)
                print(f"ç¬¬ {record_index+1} æ¡è®°å½•ï¼šæˆåŠŸæ›¿æ¢<unused98>æ ‡ç­¾")
        
        self.stats['prompt_type']['processed'] += 1
        return record
    
    def process_fields_type(self, record: Dict, record_index: int) -> Dict:
        """å¤„ç†fieldsç±»å‹çš„æ•°æ®"""
        self.stats['fields_type']['total'] += 1
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€éœ€çš„å­—æ®µ
        required_fields = ['above_functions', 'source_method_code', 'below_functions']
        missing_fields = [field for field in required_fields if field not in record]
        
        if missing_fields:
            print(f"è­¦å‘Šï¼šç¬¬ {record_index+1} æ¡è®°å½•ç¼ºå°‘å­—æ®µ: {missing_fields}")
            record['text'] = ""
            record['concatenation_status'] = f"ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}"
            self.stats['fields_type']['missing_fields'] += 1
            return record
        
        # æ‹¼æ¥å­—æ®µ
        try:
            concatenated_text = self.concatenate_fields(record)
            record['text'] = concatenated_text
            record['concatenation_status'] = "æˆåŠŸæ‹¼æ¥"
            self.stats['fields_type']['processed'] += 1
        except Exception as e:
            print(f"è­¦å‘Šï¼šç¬¬ {record_index+1} æ¡è®°å½•æ‹¼æ¥å¤±è´¥: {e}")
            record['text'] = ""
            record['concatenation_status'] = f"æ‹¼æ¥å¤±è´¥: {str(e)}"
            self.stats['fields_type']['skipped'] += 1
        
        return record
    
    def process_file(self, input_file: str, file_type: str = 'auto') -> bool:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            file_type: æ–‡ä»¶ç±»å‹ ('prompt', 'fields', 'auto')
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
        
        # è¯»å–æ•°æ®
        try:
            data = []
            with open(input_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        record = json.loads(line)
                        data.append(record)
                    except json.JSONDecodeError as e:
                        print(f"ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}")
                        continue
            
            print(f"æˆåŠŸè¯»å– {len(data)} æ¡è®°å½•")
            
            if len(data) == 0:
                print("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•è®°å½•")
                return False
                
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        # å¤„ç†æ¯æ¡è®°å½•
        for i, record in enumerate(data):
            # æ ‡å‡†åŒ–å­—æ®µå
            record = self.standardize_fields(record, i)
            
            # ç”ŸæˆID
            file_path = record.get('path', '')
            if file_path:
                record['id'] = self.generate_stable_id(file_path)
                self.stats['id_generated'] += 1
                print(f"ç¬¬ {i+1} æ¡è®°å½•ï¼šåŸºäºè·¯å¾„ '{file_path}' ç”ŸæˆID: {record['id'][:8]}...")
            else:
                record['id'] = self.generate_stable_id("")
                self.stats['id_generated'] += 1
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹æˆ–è‡ªåŠ¨æ£€æµ‹è¿›è¡Œå¤„ç†
            if file_type == 'auto':
                data_type = self.detect_data_type(record)
            else:
                data_type = file_type
            
            if data_type == 'prompt':
                record = self.process_prompt_type(record, i)
            elif data_type == 'fields':
                record = self.process_fields_type(record, i)
            else:
                print(f"è­¦å‘Šï¼šç¬¬ {i+1} æ¡è®°å½•æ— æ³•è¯†åˆ«æ•°æ®ç±»å‹ï¼Œè·³è¿‡å¤„ç†")
                record['text'] = ""
                record['processing_status'] = "æœªçŸ¥æ•°æ®ç±»å‹"
            
            if (i + 1) % 100 == 0:
                print(f"å·²å¤„ç† {i + 1}/{len(data)} æ¡è®°å½•")
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        input_path = Path(input_file)
        output_file = self.output_dir / f"{input_path.stem}_processed.jsonl"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for record in data:
                    json.dump(record, f, ensure_ascii=False)
                    f.write('\n')
            print(f"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def process_directory(self, input_dir: str, file_type: str = 'auto') -> None:
        """
        å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
        
        Args:
            input_dir: è¾“å…¥ç›®å½•è·¯å¾„
            file_type: æ–‡ä»¶ç±»å‹ ('prompt', 'fields', 'auto')
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ç›®å½•: {input_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰JSONLæ–‡ä»¶
        input_path = Path(input_dir)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        jsonl_files = []
        for ext in ['*.jsonl', '*.json']:
            jsonl_files.extend(list(input_path.glob(ext)))
        
        if not jsonl_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•JSONLæ–‡ä»¶")
            return
        
        print(f"æ‰¾åˆ° {len(jsonl_files)} ä¸ªæ–‡ä»¶")
        
        # æ‰¹é‡å¤„ç†
        successful_files = 0
        for i, file_path in enumerate(jsonl_files, 1):
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i}/{len(jsonl_files)}: {file_path.name}")
            
            if self.process_file(str(file_path), file_type):
                successful_files += 1
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self.print_stats()
        print(f"\nğŸ¯ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {successful_files}/{len(jsonl_files)} ä¸ªæ–‡ä»¶")
    
    def print_stats(self) -> None:
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å¤„ç†ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        
        print(f"ğŸ“ Promptç±»å‹æ•°æ®:")
        print(f"   æ€»è®°å½•æ•°: {self.stats['prompt_type']['total']}")
        print(f"   æˆåŠŸå¤„ç†: {self.stats['prompt_type']['processed']}")
        print(f"   è·³è¿‡è®°å½•: {self.stats['prompt_type']['skipped']}")
        print(f"   æ›¿æ¢æ ‡ç­¾: {self.stats['prompt_type']['unused98_replaced']}")
        print(f"   æå–å¤–éƒ¨: {self.stats['prompt_type']['external_imported']}")
        
        print(f"\nğŸ”— Fieldsç±»å‹æ•°æ®:")
        print(f"   æ€»è®°å½•æ•°: {self.stats['fields_type']['total']}")
        print(f"   æˆåŠŸå¤„ç†: {self.stats['fields_type']['processed']}")
        print(f"   è·³è¿‡è®°å½•: {self.stats['fields_type']['skipped']}")
        print(f"   ç¼ºå°‘å­—æ®µ: {self.stats['fields_type']['missing_fields']}")
        
        print(f"\nğŸ†” é€šç”¨å¤„ç†:")
        print(f"   ç”ŸæˆIDæ•°: {self.stats['id_generated']}")
        print(f"   å­—æ®µé‡å‘½å: {self.stats['fields_renamed']}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç»Ÿä¸€çš„æ–‡æœ¬å¤„ç†è„šæœ¬ï¼Œæ”¯æŒpromptå’Œfieldsä¸¤ç§æ•°æ®æ ¼å¼çš„æ‹¼æ¥'
    )
    parser.add_argument('--prompt-dir', help='åŒ…å«promptæ ¼å¼æ•°æ®çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--fields-dir', help='åŒ…å«fieldsæ ¼å¼æ•°æ®çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--single-file', help='å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆè‡ªåŠ¨æ£€æµ‹ç±»å‹ï¼‰')
    parser.add_argument('--output-dir', default='unified_output', help='ç»Ÿä¸€è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: unified_outputï¼‰')
    parser.add_argument('--file-type', choices=['prompt', 'fields', 'auto'], default='auto', 
                       help='å¼ºåˆ¶æŒ‡å®šæ–‡ä»¶ç±»å‹ï¼ˆé»˜è®¤: autoè‡ªåŠ¨æ£€æµ‹ï¼‰')
    
    args = parser.parse_args()
    
    if not any([args.prompt_dir, args.fields_dir, args.single_file]):
        print("âŒ è¯·è‡³å°‘æŒ‡å®šä¸€ä¸ªè¾“å…¥æº: --prompt-dir, --fields-dir, æˆ– --single-file")
        return
    
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    current_dir = Path(__file__).parent
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    output_dir = Path(args.output_dir)
    if not output_dir.is_absolute():
        output_dir = current_dir / output_dir
    
    processor = UnifiedTextProcessor(str(output_dir))
    
    # å¤„ç†å•ä¸ªæ–‡ä»¶
    if args.single_file:
        file_path = Path(args.single_file)
        if not file_path.is_absolute():
            file_path = current_dir / file_path
        
        if file_path.exists():
            processor.process_file(str(file_path), args.file_type)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # å¤„ç†promptæ ¼å¼æ•°æ®ç›®å½•
    if args.prompt_dir:
        prompt_dir = Path(args.prompt_dir)
        if not prompt_dir.is_absolute():
            prompt_dir = current_dir / prompt_dir
        
        print(f"ğŸ” å¤„ç†promptæ ¼å¼æ•°æ®...")
        processor.process_directory(str(prompt_dir), 'prompt')
    
    # å¤„ç†fieldsæ ¼å¼æ•°æ®ç›®å½•
    if args.fields_dir:
        fields_dir = Path(args.fields_dir)
        if not fields_dir.is_absolute():
            fields_dir = current_dir / fields_dir
        
        print(f"\nğŸ”— å¤„ç†fieldsæ ¼å¼æ•°æ®...")
        processor.process_directory(str(fields_dir), 'fields')
    
    print(f"\nğŸ¯ æ‰€æœ‰å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
