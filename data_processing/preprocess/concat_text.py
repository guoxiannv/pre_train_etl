#!/usr/bin/env python3
"""
ç»Ÿä¸€æ–‡æœ¬æ‹¼æ¥å¤„ç†å™¨
åˆå¹¶äº†ä¸¤ç§ä¸åŒçš„æ•°æ®å¤„ç†é€»è¾‘ï¼š
1. Fieldså¤„ç†å™¨ï¼šæ‹¼æ¥ above_functions + source_method_code + below_functions å­—æ®µ
2. Promptå¤„ç†å™¨ï¼šä»promptå­—æ®µä¸­æå–ä¸‰æ®µå†…å®¹å¹¶å¤„ç†<unused98>æ ‡ç­¾æ›¿æ¢

æ”¯æŒè‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹æˆ–æ‰‹åŠ¨æŒ‡å®šå¤„ç†æ¨¡å¼
è¾“å…¥ï¼šbg_data_selectï¼ˆFieldsæ ¼å¼ï¼‰å’Œ bg_dataï¼ˆPromptæ ¼å¼ï¼‰
è¾“å‡ºï¼štrans_text_data
"""

import json
import re
import os
import sys
import hashlib
from pathlib import Path
from typing import List, Dict, Tuple
import argparse


def concatenate_fields(record: Dict) -> str:
    """
    æ‹¼æ¥ä¸‰ä¸ªå­—æ®µï¼šabove_functions + source_method_code + below_functions
    
    Args:
        record: åŒ…å«å­—æ®µçš„å­—å…¸è®°å½•
        
    Returns:
        æ‹¼æ¥åçš„textå­—ç¬¦ä¸²
    """
    # è·å–ä¸‰ä¸ªå­—æ®µçš„å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®¾ä¸ºç©ºå­—ç¬¦ä¸²
    above_functions = record.get('above_functions', '')
    source_method_code = record.get('source_method_code', '')
    below_functions = record.get('below_functions', '')
    
    # æ™ºèƒ½å¤„ç†å­—æ®µå€¼ï¼Œè½¬æ¢ä¸ºåˆé€‚çš„å­—ç¬¦ä¸²ï¼Œä¿ç•™åŸå§‹ç©ºæ ¼
    def process_field_value(value):
        if value is None:
            return ''
        elif isinstance(value, str):
            # ä¿ç•™åŸå§‹ç©ºæ ¼ï¼Œä¸ä½¿ç”¨strip()
            return value
        elif isinstance(value, (list, tuple)):
            # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œä¸”ä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
            if len(value) == 0:
                return ''
            # å¦‚æœåˆ—è¡¨åŒ…å«å­—ç¬¦ä¸²å…ƒç´ ï¼Œç”¨æ¢è¡Œç¬¦è¿æ¥ï¼Œä¿ç•™æ¯ä¸ªå…ƒç´ çš„åŸå§‹ç©ºæ ¼
            elif all(isinstance(item, str) for item in value):
                return '\n'.join(item for item in value if item)  # ä¸ä½¿ç”¨strip()
            # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            else:
                return str(value)
        elif isinstance(value, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆå»é™¤é¦–å°¾çš„{}ï¼‰
            try:
                json_str = json.dumps(value, ensure_ascii=False)
                return json_str[1:-1] if json_str.startswith('{') and json_str.endswith('}') else json_str
            except:
                return str(value)
        else:
            # å…¶ä»–ç±»å‹ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return str(value)
    
    # å¤„ç†ä¸‰ä¸ªå­—æ®µ
    above_functions = process_field_value(above_functions)
    source_method_code = process_field_value(source_method_code)
    below_functions = process_field_value(below_functions)
    
    # ç›´æ¥æ‹¼æ¥ä¸‰ä¸ªå­—æ®µï¼Œä¿ç•™åŸæœ‰çš„ç©ºæ ¼å’Œæ¢è¡Œ
    concatenated_text = above_functions + source_method_code + below_functions
    
    return concatenated_text


def extract_text_from_prompt(prompt: str) -> str:
    """
    ä»promptä¸­æå–ä¸‰æ®µå†…å®¹å¹¶æ‹¼æ¥ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼æ ¼å¼
    
    Args:
        prompt: åŒ…å«ä¸‰æ®µä»£ç çš„promptå­—ç¬¦ä¸²
        
    Returns:
        æ‹¼æ¥åçš„textå­—ç¬¦ä¸²
    """
    if not prompt or not isinstance(prompt, str):
        return ""
    
    try:
        # å®šä¹‰æå–æ¨¡å¼ï¼Œä¿ç•™å‰åç©ºæ ¼
        patterns = {
            'first': r'The context above the method is:\n```arkts\n(.*?)```\n\nAnd here is the code snippet you are asked to complete',
            'second': r'And here is the code snippet you are asked to complete:\n```arkts\n(.*?)```\n\nEnsure that only missing codes',
            'third': r'The context below the method is:\n```arkts\n(.*?)```\n\nThe context above the method is'
        }
        
        extracted_parts = {}
        
        # æå–ä¸‰æ®µå†…å®¹ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼
        for part_name, pattern in patterns.items():
            match = re.search(pattern, prompt, re.DOTALL)
            if match:
                # ä¸ä½¿ç”¨strip()ï¼Œä¿ç•™åŸæœ‰ç©ºæ ¼
                extracted_parts[part_name] = match.group(1)
            else:
                extracted_parts[part_name] = ""
        
        # æ‹¼æ¥ä¸‰æ®µå†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼
        combined_text = (
            extracted_parts.get('first', '') + '\n\n' + 
            extracted_parts.get('second', '') + '\n\n' + 
            extracted_parts.get('third', '')
        )
        
        # åªåœ¨æœ€åå»é™¤é¦–å°¾çš„ç©ºç™½è¡Œï¼Œä½†ä¿ç•™å†…å®¹ä¸­çš„ç©ºæ ¼
        return combined_text.rstrip('\n')
        
    except Exception as e:
        print(f"æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return ""


def extract_external_imported(prompt: str) -> str:
    """
    ä»promptä¸­æå–external_importedä¿¡æ¯
    
    Args:
        prompt: promptå­—ç¬¦ä¸²
        
    Returns:
        æå–çš„external_importedå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not prompt or not isinstance(prompt, str):
        return ""
    
    try:
        # åŒ¹é… "Below are some information from external classes imported by current file:\n```arkts" åˆ° "```" ä¹‹é—´çš„å†…å®¹
        pattern = r'Below are some information from external classes imported by current file:\n```arkts\n(.*?)\n```'
        match = re.search(pattern, prompt, re.DOTALL)
        
        if match:
            # ä¿ç•™åŸæœ‰ç©ºæ ¼ï¼Œä¸ä½¿ç”¨strip()
            return match.group(1)
        else:
            return ""
            
    except Exception as e:
        print(f"æå–external_importedæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return ""


def extract_response_code(response: str) -> str:
    """
    ä»responseå­—æ®µä¸­æå–```arkts\nå’Œ\n```ä¹‹é—´çš„ä»£ç å†…å®¹ï¼Œä¿ç•™ç©ºæ ¼
    
    Args:
        response: responseå­—æ®µå­—ç¬¦ä¸²
        
    Returns:
        æå–çš„ä»£ç å†…å®¹
    """
    if not response or not isinstance(response, str):
        return ""
    
    try:
        # åŒ¹é…```arkts\nå’Œ\n```ä¹‹é—´çš„å†…å®¹
        pattern = r'```arkts\n(.*?)\n```'
        match = re.search(pattern, response, re.DOTALL)
        
        if match:
            # ä¿ç•™åŸæœ‰ç©ºæ ¼ï¼Œä¸ä½¿ç”¨strip()
            return match.group(1)
        else:
            return ""
            
    except Exception as e:
        print(f"æå–responseä»£ç æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return ""


def replace_unused98_tags(text: str, response_code: str) -> str:
    """
    å°†æ–‡æœ¬ä¸­çš„<unused98>æ ‡ç­¾æ›¿æ¢æˆresponseä»£ç ï¼Œä¿ç•™ç©ºæ ¼æ ¼å¼
    
    Args:
        text: åŒ…å«<unused98>æ ‡ç­¾çš„æ–‡æœ¬
        response_code: è¦æ›¿æ¢çš„ä»£ç å†…å®¹
        
    Returns:
        æ›¿æ¢åçš„æ–‡æœ¬
    """
    if not text or not isinstance(text, str):
        return text
    
    if not response_code:
        return text
    
    try:
        # æ›¿æ¢æ‰€æœ‰<unused98>æ ‡ç­¾
        replaced_text = text.replace('<unused98>', response_code)
        
        return replaced_text
        
    except Exception as e:
        print(f"æ›¿æ¢<unused98>æ ‡ç­¾æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return text


def generate_stable_id(file_path: str) -> str:
    """
    åŸºäºæ–‡ä»¶è·¯å¾„ç”Ÿæˆç¨³å®šçš„ID
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
        
    Returns:
        64ä½åå…­è¿›åˆ¶SHA256å“ˆå¸ŒID
    """
    if not file_path or not isinstance(file_path, str):
        # å¦‚æœæ²¡æœ‰è·¯å¾„ï¼Œç”Ÿæˆä¸€ä¸ªéšæœºID
        import uuid
        return str(uuid.uuid4())
    
    try:
        # ä½¿ç”¨SHA256å“ˆå¸Œç”Ÿæˆç¨³å®šID
        stable_id = hashlib.sha256(file_path.encode('utf-8')).hexdigest()
        return stable_id
    except Exception as e:
        print(f"ç”ŸæˆIDæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # å‡ºé”™æ—¶ç”ŸæˆéšæœºID
        import uuid
        return str(uuid.uuid4())


def extract_project_info_from_repo_url(repo_url: str) -> tuple:
    """
    ä»repoUrlä¸­æå–project_nameå’Œpathä¿¡æ¯
    
    Args:
        repo_url: ä»“åº“URLå­—ç¬¦ä¸²
        
    Returns:
        (project_name, path) å…ƒç»„ï¼Œä¸¤è€…éƒ½æ˜¯repo_name
    """
    if not repo_url or not isinstance(repo_url, str):
        return "", ""
    
    try:
        # ç§»é™¤.gitåç¼€
        if repo_url.endswith('.git'):
            repo_url = repo_url[:-4]
        
        # åˆ†å‰²URLï¼Œè·å–æœ€åä¸€éƒ¨åˆ†
        parts = repo_url.split('/')
        if len(parts) >= 1:
            # è·å–æœ€åä¸€éƒ¨åˆ†ï¼šrepo_name
            repo_name = parts[-1]  # repo_name
            # project_nameå’Œpathéƒ½ä½¿ç”¨repo_name
            return repo_name, repo_name
        else:
            return "", ""
    except Exception as e:
        print(f"è§£ærepoUrlæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return "", ""


def detect_data_type(record: Dict) -> str:
    """
    è‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹ï¼ˆä»…ç”¨äºå•ä¸ªæ–‡ä»¶å¤„ç†ï¼‰
    
    Args:
        record: æ•°æ®è®°å½•
        
    Returns:
        'fields' æˆ– 'prompt'
    """
    # æ£€æŸ¥æ˜¯å¦åŒ…å«fieldsæ ¼å¼çš„å¿…éœ€å­—æ®µ
    fields_required = ['above_functions', 'source_method_code', 'below_functions']
    has_fields = all(field in record for field in fields_required)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«promptå­—æ®µ
    has_prompt = 'prompt' in record
    
    if has_fields:
        return 'fields'
    elif has_prompt:
        return 'prompt'
    else:
        print(f"è­¦å‘Šï¼šæ— æ³•è¯†åˆ«æ•°æ®ç±»å‹ï¼Œè®°å½•åŒ…å«å­—æ®µ: {list(record.keys())}")
        return 'fields'  # é»˜è®¤è¿”å›fields


def safe_json_loads(line: str, line_num: int) -> dict:
    """
    å®‰å…¨åœ°è§£æJSONè¡Œï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    
    Args:
        line: JSONå­—ç¬¦ä¸²
        line_num: è¡Œå·ï¼ˆç”¨äºé”™è¯¯æŠ¥å‘Šï¼‰
        
    Returns:
        è§£æåçš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºå­—å…¸
    """
    try:
        return json.loads(line.strip())
    except json.JSONDecodeError as e:
        print(f"ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}")
        print(f"é—®é¢˜è¡Œå†…å®¹: {line[:100]}...")  # åªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
        return {}
    except Exception as e:
        print(f"ç¬¬ {line_num} è¡Œå¤„ç†å¤±è´¥: {e}")
        return {}


def process_fields_record(record: Dict, record_index: int) -> Tuple[bool, Dict]:
    """
    å¤„ç†Fieldsæ ¼å¼çš„è®°å½•
    
    Args:
        record: æ•°æ®è®°å½•
        record_index: è®°å½•ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, ç»Ÿè®¡ä¿¡æ¯)
    """
    stats = {
        'processed': 0,
        'skipped': 0,
        'missing_fields': 0,
        'id_generated': 0,
        'fields_renamed': 0
    }
    
    # å­—æ®µåæ ‡å‡†åŒ–ï¼šå°†projectNameæ”¹ä¸ºproject_nameï¼Œå°†filePathæ”¹ä¸ºpath
    if 'projectName' in record:
        record['project_name'] = record.pop('projectName')
        stats['fields_renamed'] += 1
    
    if 'filePath' in record:
        record['path'] = record.pop('filePath')
        stats['fields_renamed'] += 1
    
    # ç”ŸæˆåŸºäºpathçš„ç¨³å®šID
    file_path = record.get('path', '')
    if file_path:
        record['id'] = generate_stable_id(file_path)
        stats['id_generated'] += 1
    else:
        record['id'] = generate_stable_id("")
        stats['id_generated'] += 1
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€éœ€çš„å­—æ®µ
    required_fields = ['above_functions', 'source_method_code', 'below_functions']
    missing_fields = [field for field in required_fields if field not in record]
    
    if missing_fields:
        record['text'] = ""
        stats['missing_fields'] += 1
        return False, stats
    
    # æ‹¼æ¥å­—æ®µ
    try:
        concatenated_text = concatenate_fields(record)
        record['text'] = concatenated_text
        stats['processed'] += 1
        return True, stats
    except Exception as e:
        record['text'] = ""
        stats['skipped'] += 1
        return False, stats


def process_prompt_record(record: Dict, record_index: int) -> Tuple[bool, Dict]:
    """
    å¤„ç†Promptæ ¼å¼çš„è®°å½•
    
    Args:
        record: æ•°æ®è®°å½•
        record_index: è®°å½•ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, ç»Ÿè®¡ä¿¡æ¯)
    """
    stats = {
        'processed': 0,
        'skipped': 0,
        'unused98_replaced': 0,
        'id_generated': 0,
        'fields_renamed': 0,
        'external_imported_extracted': 0,
        'unused98_not_replaced': 0,
        'unused98_not_replaced_ids': []
    }
    
    if 'prompt' not in record:
        record['text'] = ""
        stats['skipped'] += 1
        return False, stats
    
    # å­—æ®µåæ ‡å‡†åŒ–å’Œå­—æ®µå€¼å¤„ç†
    # 1. å¤„ç†projectNameå­—æ®µ
    if 'projectName' in record:
        # å¦‚æœå­˜åœ¨projectNameï¼Œé‡å‘½åä¸ºproject_name
        record['project_name'] = record.pop('projectName')
        stats['fields_renamed'] += 1
    elif 'project_name' not in record:
        # å¦‚æœæ—¢æ²¡æœ‰projectNameä¹Ÿæ²¡æœ‰project_nameï¼Œä»repoUrlæå–
        repo_url = record.get('repoUrl', '')
        if repo_url:
            project_name, _ = extract_project_info_from_repo_url(repo_url)
            if project_name:
                record['project_name'] = project_name
    
    # 2. å¤„ç†relativePathå­—æ®µ
    if 'relativePath' in record:
        # å¦‚æœå­˜åœ¨relativePathï¼Œé‡å‘½åä¸ºpath
        record['path'] = record.pop('relativePath')
        stats['fields_renamed'] += 1
    elif 'path' not in record:
        # å¦‚æœæ—¢æ²¡æœ‰relativePathä¹Ÿæ²¡æœ‰pathï¼Œä»repoUrlæå–
        repo_url = record.get('repoUrl', '')
        if repo_url:
            _, path = extract_project_info_from_repo_url(repo_url)
            if path:
                record['path'] = path
    
    # ç”ŸæˆåŸºäºpathçš„ç¨³å®šID
    file_path = record.get('path', '')
    if file_path:
        record['id'] = generate_stable_id(file_path)
        stats['id_generated'] += 1
    else:
        record['id'] = generate_stable_id("")
        stats['id_generated'] += 1
    
    # æå–textå†…å®¹
    text_content = extract_text_from_prompt(record['prompt'])
    record['text'] = text_content
    
    # æå–external_importedå†…å®¹
    external_imported_content = extract_external_imported(record['prompt'])
    record['external_imported'] = external_imported_content
    if external_imported_content:  # å¦‚æœæå–åˆ°å†…å®¹ï¼Œå¢åŠ è®¡æ•°
        stats['external_imported_extracted'] += 1
    
    stats['processed'] += 1
    
    # å¤„ç†<unused98>æ ‡ç­¾æ›¿æ¢
    replacement_failed = False
    if '<unused98>' in text_content:
        if 'response' in record:
            response_code = extract_response_code(record['response'])
            if response_code:
                replaced_text = replace_unused98_tags(text_content, response_code)
                record['text'] = replaced_text
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ›¿æ¢çš„æ ‡ç­¾
                if '<unused98>' in replaced_text:
                    stats['unused98_not_replaced'] += 1
                    stats['unused98_not_replaced_ids'].append(record.get('id', 'unknown'))
                    replacement_failed = True
                    print(f"è­¦å‘Šï¼šè®°å½•ID {record.get('id', 'unknown')} çš„<unused98>æ ‡ç­¾éƒ¨åˆ†æ›¿æ¢å¤±è´¥ï¼Œä»æœ‰å‰©ä½™æ ‡ç­¾")
                else:
                    stats['unused98_replaced'] += 1
            else:
                # responseå­—æ®µå­˜åœ¨ä½†æ— æ³•æå–ä»£ç ï¼Œè®°å½•ä¸ºæœªæ›¿æ¢
                stats['unused98_not_replaced'] += 1
                stats['unused98_not_replaced_ids'].append(record.get('id', 'unknown'))
                replacement_failed = True
                print(f"è­¦å‘Šï¼šè®°å½•ID {record.get('id', 'unknown')} çš„responseå­—æ®µæ— æ³•æå–ä»£ç ï¼Œ<unused98>æ ‡ç­¾æœªæ›¿æ¢")
        else:
            # æ²¡æœ‰responseå­—æ®µï¼Œè®°å½•ä¸ºæœªæ›¿æ¢
            stats['unused98_not_replaced'] += 1
            stats['unused98_not_replaced_ids'].append(record.get('id', 'unknown'))
            replacement_failed = True
            print(f"è­¦å‘Šï¼šè®°å½•ID {record.get('id', 'unknown')} ç¼ºå°‘responseå­—æ®µï¼Œ<unused98>æ ‡ç­¾æœªæ›¿æ¢")
    
    # å¦‚æœæ›¿æ¢å¤±è´¥ï¼Œè·³è¿‡è¿™æ¡è®°å½•
    if replacement_failed:
        return False, stats
    
    return True, stats


def process_jsonl_file(input_file: str, output_dir: str, data_type: str) -> dict:
    """
    å¤„ç†å•ä¸ªJSONLæ–‡ä»¶ï¼Œä½¿ç”¨æŒ‡å®šçš„æ•°æ®ç±»å‹
    
    Args:
        input_file: è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        data_type: æ•°æ®ç±»å‹ ('fields' æˆ– 'prompt')
        
    Returns:
        å¤„ç†ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
    
    # è¯»å–æ•°æ®
    try:
        data = []
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:  # è·³è¿‡ç©ºè¡Œ
                    continue
                
                record = safe_json_loads(line, line_num)
                if record:  # åªæ·»åŠ æˆåŠŸè§£æçš„è®°å½•
                    data.append(record)
                else:
                    print(f"è·³è¿‡ç¬¬ {line_num} è¡Œï¼ˆè§£æå¤±è´¥ï¼‰")
        
        print(f"æˆåŠŸè¯»å– {len(data)} æ¡æœ‰æ•ˆè®°å½•")
        
        if len(data) == 0:
            print("æ²¡æœ‰æˆåŠŸè§£æä»»ä½•è®°å½•ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
            return {
                'total': 0,
                'fields_processed': 0,
                'prompt_processed': 0,
                'skipped': 0,
                'unknown_type': 0
            }
            
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return {'total': 0, 'fields_processed': 0, 'prompt_processed': 0, 'skipped': 0, 'unknown_type': 0}
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return {'total': 0, 'fields_processed': 0, 'prompt_processed': 0, 'skipped': 0, 'unknown_type': 0}
    
    # å¤„ç†æ¯æ¡è®°å½•
    stats = {
        'total': len(data),
        'fields_processed': 0,
        'prompt_processed': 0,
        'skipped': 0,
        'unknown_type': 0,
        'fields_missing_fields': 0,
        'unused98_replaced': 0,
        'id_generated': 0,
        'fields_renamed': 0,
        'external_imported_extracted': 0,
        'unused98_not_replaced': 0,
        'unused98_not_replaced_ids': []
    }
    
    for i, record in enumerate(data):
        # æ ¹æ®æŒ‡å®šçš„æ•°æ®ç±»å‹å¤„ç†è®°å½•
        if data_type == 'fields':
            success, record_stats = process_fields_record(record, i)
            if success:
                stats['fields_processed'] += 1
            stats['fields_missing_fields'] += record_stats.get('missing_fields', 0)
            stats['id_generated'] += record_stats.get('id_generated', 0)
            stats['fields_renamed'] += record_stats.get('fields_renamed', 0)
            
        elif data_type == 'prompt':
            success, record_stats = process_prompt_record(record, i)
            if success:
                stats['prompt_processed'] += 1
            stats['unused98_replaced'] += record_stats.get('unused98_replaced', 0)
            stats['id_generated'] += record_stats.get('id_generated', 0)
            stats['fields_renamed'] += record_stats.get('fields_renamed', 0)
            stats['external_imported_extracted'] += record_stats.get('external_imported_extracted', 0)
            stats['unused98_not_replaced'] += record_stats.get('unused98_not_replaced', 0)
            stats['unused98_not_replaced_ids'].extend(record_stats.get('unused98_not_replaced_ids', []))
            
        else:
            record['text'] = ""
            stats['unknown_type'] += 1
            stats['skipped'] += 1
        
        if (i + 1) % 1000 == 0:
            print(f"å·²å¤„ç† {i + 1}/{len(data)} æ¡è®°å½•")
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    input_path = Path(input_file)
    base_name = input_path.stem
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®ï¼ˆåªä¿å­˜æˆåŠŸå¤„ç†çš„è®°å½•ï¼‰
    output_file = Path(output_dir) / f"{base_name}_with_text.jsonl"
    try:
        saved_count = 0
        with open(output_file, 'w', encoding='utf-8') as f:
            for record in data:
                # æ£€æŸ¥è®°å½•æ˜¯å¦æˆåŠŸå¤„ç†ï¼ˆæœ‰textå­—æ®µä¸”ä¸ä¸ºç©ºï¼Œæˆ–è€…æ²¡æœ‰<unused98>æ ‡ç­¾ï¼‰
                if data_type == 'prompt':
                    # promptæ ¼å¼ï¼šéœ€è¦æœ‰textå­—æ®µï¼Œä¸”å¦‚æœåŸæœ¬æœ‰<unused98>æ ‡ç­¾åˆ™å¿…é¡»æˆåŠŸæ›¿æ¢
                    if 'text' in record and record['text']:
                        # å¦‚æœtextä¸­ä»æœ‰<unused98>æ ‡ç­¾ï¼Œè¯´æ˜æ›¿æ¢å¤±è´¥ï¼Œè·³è¿‡
                        if '<unused98>' not in record['text']:
                            json.dump(record, f, ensure_ascii=False)
                            f.write('\n')
                            saved_count += 1
                elif data_type == 'fields':
                    # fieldsæ ¼å¼ï¼šæœ‰textå­—æ®µå³å¯
                    if 'text' in record:
                        json.dump(record, f, ensure_ascii=False)
                        f.write('\n')
                        saved_count += 1
                else:
                    # å…¶ä»–ç±»å‹ï¼Œç›´æ¥ä¿å­˜
                    json.dump(record, f, ensure_ascii=False)
                    f.write('\n')
                    saved_count += 1
        
        print(f"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        print(f"âœ… å®é™…ä¿å­˜è®°å½•æ•°: {saved_count}/{len(data)}")
        if saved_count < len(data):
            print(f"âš ï¸  è¿‡æ»¤æ‰äº† {len(data) - saved_count} æ¡æ›¿æ¢å¤±è´¥çš„è®°å½•")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return stats
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ¯ å¤„ç†å®Œæˆï¼")
    print(f"æ€»è®°å½•æ•°: {stats['total']}")
    print(f"Fieldsæ ¼å¼å¤„ç†: {stats['fields_processed']}")
    print(f"Promptæ ¼å¼å¤„ç†: {stats['prompt_processed']}")
    print(f"è·³è¿‡è®°å½•: {stats['skipped']}")
    print(f"æœªçŸ¥ç±»å‹: {stats['unknown_type']}")
    print(f"ç¼ºå°‘å­—æ®µ: {stats['fields_missing_fields']}")
    print(f"æ›¿æ¢æ ‡ç­¾: {stats['unused98_replaced']}")
    print(f"ç”ŸæˆID: {stats['id_generated']}")
    print(f"å­—æ®µé‡å‘½å: {stats['fields_renamed']}")
    print(f"æå–external_imported: {stats['external_imported_extracted']}")
    print(f"æ ‡ç­¾æ›¿æ¢å¤±è´¥: {stats['unused98_not_replaced']}")
    
    # è¾“å‡ºæ›¿æ¢å¤±è´¥çš„è®°å½•ID
    if stats['unused98_not_replaced'] > 0:
        print(f"æ ‡ç­¾æ›¿æ¢å¤±è´¥çš„è®°å½•ID: {stats['unused98_not_replaced_ids']}")
    
    return stats


def get_jsonl_files(input_dir: str) -> List[str]:
    """
    è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        
    Returns:
        JSONLæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    jsonl_files = []
    
    try:
        input_path = Path(input_dir)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return jsonl_files
        
        # æŸ¥æ‰¾æ‰€æœ‰.jsonlæ–‡ä»¶
        for file_path in input_path.glob("*.jsonl"):
            jsonl_files.append(str(file_path))
        
        # ä¹ŸæŸ¥æ‰¾.jsonæ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        for file_path in input_path.glob("*.json"):
            jsonl_files.append(str(file_path))
        
        print(f"åœ¨ {input_dir} ç›®å½•ä¸‹æ‰¾åˆ° {len(jsonl_files)} ä¸ªJSONLæ–‡ä»¶")
        
    except Exception as e:
        print(f"è·å–JSONLæ–‡ä»¶åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    return jsonl_files


def batch_process_directory(input_dir: str, output_dir: str, data_type: str) -> dict:
    """
    æ‰¹é‡å¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        data_type: æ•°æ®ç±»å‹ ('fields' æˆ– 'prompt')
        
    Returns:
        æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†ç›®å½•: {input_dir}")
    
    # è·å–æ‰€æœ‰JSONLæ–‡ä»¶
    jsonl_files = get_jsonl_files(input_dir)
    
    if not jsonl_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•JSONLæ–‡ä»¶")
        return {
            'total_files': 0,
            'total_records': 0,
            'total_fields_processed': 0,
            'total_prompt_processed': 0,
            'total_skipped': 0
        }
    
    # æ‰¹é‡å¤„ç†
    total_stats = {
        'total_files': len(jsonl_files),
        'total_records': 0,
        'total_fields_processed': 0,
        'total_prompt_processed': 0,
        'total_skipped': 0,
        'total_unknown_type': 0,
        'total_fields_missing_fields': 0,
        'total_unused98_replaced': 0,
        'total_id_generated': 0,
        'total_fields_renamed': 0,
        'total_external_imported_extracted': 0,
        'total_unused98_not_replaced': 0,
        'total_unused98_not_replaced_ids': []
    }
    
    for i, input_file in enumerate(jsonl_files, 1):
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i}/{len(jsonl_files)}: {os.path.basename(input_file)}")
        
        # å¤„ç†æ–‡ä»¶
        stats = process_jsonl_file(input_file, output_dir, data_type)
        
        # ç´¯è®¡ç»Ÿè®¡ä¿¡æ¯
        total_stats['total_records'] += stats['total']
        total_stats['total_fields_processed'] += stats['fields_processed']
        total_stats['total_prompt_processed'] += stats['prompt_processed']
        total_stats['total_skipped'] += stats['skipped']
        total_stats['total_unknown_type'] += stats['unknown_type']
        total_stats['total_fields_missing_fields'] += stats.get('fields_missing_fields', 0)
        total_stats['total_unused98_replaced'] += stats.get('unused98_replaced', 0)
        total_stats['total_id_generated'] += stats.get('id_generated', 0)
        total_stats['total_fields_renamed'] += stats.get('fields_renamed', 0)
        total_stats['total_external_imported_extracted'] += stats.get('external_imported_extracted', 0)
        total_stats['total_unused98_not_replaced'] += stats.get('unused98_not_replaced', 0)
        total_stats['total_unused98_not_replaced_ids'].extend(stats.get('unused98_not_replaced_ids', []))
        
        print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(input_file)}")
    
    return total_stats


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€æ–‡æœ¬æ‹¼æ¥å¤„ç†å™¨ - æ”¯æŒFieldså’ŒPromptä¸¤ç§æ•°æ®æ ¼å¼')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--output-dir', default='trans_text_data', 
                       help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: trans_text_dataï¼‰')
    parser.add_argument('--single-file', help='å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    
    # å¤„ç†æ¨¡å¼å‚æ•°
    parser.add_argument('--fields-only', action='store_true', 
                       help='åªå¤„ç†Fieldsæ ¼å¼æ•°æ®ï¼ˆé»˜è®¤ä»bg_data_selectè¯»å–ï¼‰')
    parser.add_argument('--prompt-only', action='store_true', 
                       help='åªå¤„ç†Promptæ ¼å¼æ•°æ®ï¼ˆé»˜è®¤ä»bg_dataè¯»å–ï¼‰')
    parser.add_argument('--both', action='store_true', 
                       help='å¤„ç†ä¸¤ç§æ ¼å¼æ•°æ®ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰')
    
    # è‡ªå®šä¹‰è¾“å…¥ç›®å½•
    parser.add_argument('--fields-dir', default='bg_data_select',
                       help='Fieldsæ ¼å¼æ•°æ®è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤: bg_data_selectï¼‰')
    parser.add_argument('--prompt-dir', default='bg_data',
                       help='Promptæ ¼å¼æ•°æ®è¾“å…¥ç›®å½•ï¼ˆé»˜è®¤: bg_dataï¼‰')
    
    # å¼ºåˆ¶æŒ‡å®šæ•°æ®ç±»å‹
    parser.add_argument('--force-type', choices=['fields', 'prompt'],
                       help='å¼ºåˆ¶æŒ‡å®šæ•°æ®ç±»å‹ï¼Œè·³è¿‡è‡ªåŠ¨æ£€æµ‹')
    
    args = parser.parse_args()
    
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    curdir = os.path.dirname(__file__)
    
    # å¤„ç†è¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    if not output_dir.is_absolute():
        output_dir = Path(curdir) / output_dir
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ¯ ç»Ÿä¸€æ–‡æœ¬æ‹¼æ¥å¤„ç†å™¨å¯åŠ¨")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 60)
    
    # å¤„ç†å•ä¸ªæ–‡ä»¶
    if args.single_file:
        if not Path(args.single_file).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.single_file}")
            return
        
        print(f"å¤„ç†å•ä¸ªæ–‡ä»¶: {args.single_file}")
        # å¯¹äºå•ä¸ªæ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰å¼ºåˆ¶æŒ‡å®šç±»å‹ï¼Œåˆ™éœ€è¦æ£€æµ‹
        if args.force_type:
            file_data_type = args.force_type
        else:
            # ç®€å•æ£€æµ‹ï¼šè¯»å–ç¬¬ä¸€æ¡è®°å½•åˆ¤æ–­ç±»å‹
            try:
                with open(args.single_file, 'r', encoding='utf-8') as f:
                    line = f.readline().strip()
                    if line:
                        record = json.loads(line)
                        file_data_type = detect_data_type(record)
                    else:
                        print("è­¦å‘Šï¼šæ–‡ä»¶ä¸ºç©ºï¼Œé»˜è®¤ä½¿ç”¨fieldsç±»å‹")
                        file_data_type = 'fields'
            except Exception as e:
                print(f"æ£€æµ‹æ–‡ä»¶ç±»å‹å¤±è´¥: {e}ï¼Œé»˜è®¤ä½¿ç”¨fieldsç±»å‹")
                file_data_type = 'fields'
        
        stats = process_jsonl_file(args.single_file, str(output_dir), file_data_type)
        return
    
    # ç¡®å®šå¤„ç†æ¨¡å¼
    process_fields = args.fields_only or args.both or (not args.prompt_only and not args.fields_only)
    process_prompt = args.prompt_only or args.both or (not args.prompt_only and not args.fields_only)
    
    overall_stats = {
        'total_files': 0,
        'total_records': 0,
        'total_fields_processed': 0,
        'total_prompt_processed': 0,
        'total_skipped': 0
    }
    
    # å¤„ç†Fieldsæ ¼å¼æ•°æ®
    if process_fields:
        fields_dir = Path(args.fields_dir)
        if not fields_dir.is_absolute():
            fields_dir = Path(curdir) / fields_dir
        
        if fields_dir.exists():
            print(f"\nğŸ”§ å¤„ç†Fieldsæ ¼å¼æ•°æ® (æ¥æº: {fields_dir})")
            fields_stats = batch_process_directory(str(fields_dir), str(output_dir), 'fields')
            
            # ç´¯è®¡ç»Ÿè®¡
            overall_stats['total_files'] += fields_stats['total_files']
            overall_stats['total_records'] += fields_stats['total_records']
            overall_stats['total_fields_processed'] += fields_stats['total_fields_processed']
            overall_stats['total_skipped'] += fields_stats['total_skipped']
        else:
            print(f"âš ï¸  Fieldsæ ¼å¼è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {fields_dir}")
    
    # å¤„ç†Promptæ ¼å¼æ•°æ®
    if process_prompt:
        prompt_dir = Path(args.prompt_dir)
        if not prompt_dir.is_absolute():
            prompt_dir = Path(curdir) / prompt_dir
        
        if prompt_dir.exists():
            print(f"\nğŸ”§ å¤„ç†Promptæ ¼å¼æ•°æ® (æ¥æº: {prompt_dir})")
            prompt_stats = batch_process_directory(str(prompt_dir), str(output_dir), 'prompt')
            
            # ç´¯è®¡ç»Ÿè®¡
            overall_stats['total_files'] += prompt_stats['total_files']
            overall_stats['total_records'] += prompt_stats['total_records']
            overall_stats['total_prompt_processed'] += prompt_stats['total_prompt_processed']
            overall_stats['total_skipped'] += prompt_stats['total_skipped']
        else:
            print(f"âš ï¸  Promptæ ¼å¼è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {prompt_dir}")
    
    # è¾“å‡ºæ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ¯ æ‰€æœ‰å¤„ç†å®Œæˆï¼")
    print(f"æ€»æ–‡ä»¶æ•°: {overall_stats['total_files']}")
    print(f"æ€»è®°å½•æ•°: {overall_stats['total_records']}")
    print(f"Fieldsæ ¼å¼å¤„ç†: {overall_stats['total_fields_processed']}")
    print(f"Promptæ ¼å¼å¤„ç†: {overall_stats['total_prompt_processed']}")
    print(f"æ€»è·³è¿‡æ•°: {overall_stats['total_skipped']}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
